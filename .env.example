# =============================================================================
# LLM Configuration
# =============================================================================
# Choose ONE provider and configure accordingly

# -----------------------------------------------------------------------------
# Ollama Configuration (Local LLM - Free)
# -----------------------------------------------------------------------------
# Ollama Model Name (e.g., ollama/llama2, ollama/mistral, ollama/codellama)
OLLAMA_MODEL_NAME=

# Ollama Base URL
# For Docker: http://ollama:11434
# For Local: http://localhost:11434
# Leave empty to auto-detect based on environment
OLLAMA_BASE_URL=

# -----------------------------------------------------------------------------
# Mistral API Configuration
# -----------------------------------------------------------------------------
# Get your API key from: https://console.mistral.ai/home?workspace_dialog=apiKeys
MISTRAL_API_KEY=

# Mistral Model Name (e.g., mistral/codestral-2508, mistral/mistral-large-latest)
MISTRAL_MODEL_NAME=

# -----------------------------------------------------------------------------
# OpenAI API Configuration
# -----------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# OpenAI Model Name (e.g., openai/gpt-4, openai/gpt-3.5-turbo)
OPENAI_MODEL_NAME=

# -----------------------------------------------------------------------------
# Anthropic API Configuration
# -----------------------------------------------------------------------------
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# Anthropic Model Name (e.g., anthropic/claude-3-opus, anthropic/claude-3-sonnet)
ANTHROPIC_MODEL_NAME=

# -----------------------------------------------------------------------------
# Groq API Configuration
# -----------------------------------------------------------------------------
# Get your API key from: https://console.groq.com/
GROQ_API_KEY=

# Groq Model Name (e.g., groq/mixtral-8x7b, groq/llama2-70b)
GROQ_MODEL_NAME=

# =============================================================================
# Docker Environment (Auto-set by Docker Compose)
# =============================================================================
# Set to 'true' when running in Docker container
DOCKER_ENV=false
